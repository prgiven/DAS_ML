{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed095956",
   "metadata": {},
   "source": [
    "# DAS Microseismic Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6fe31a",
   "metadata": {},
   "source": [
    "### Written by Paige Given and Fantine Huot with Contributions from Ariel Lellouch, Bin Luo, Robert G. Clapp, Tamas Nemeth, Kurt Nihei, and Biondo L. Biondi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa4dbac",
   "metadata": {},
   "source": [
    "#### This notebook runs through the entire processing and prediction process for our ML workflow. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7453607e",
   "metadata": {},
   "source": [
    "## Load dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3a7b10",
   "metadata": {},
   "outputs": [],
   "source": [
    " cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1eaeae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import scipy\n",
    "import math\n",
    "from obspy.signal.filter import bandpass\n",
    "import matplotlib.pyplot as plt\n",
    "import enum\n",
    "import os\n",
    "from typing import List, Sequence, Text, Tuple\n",
    "import logging\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acbbf3f",
   "metadata": {},
   "source": [
    "## Check for visible GPU devices\n",
    "#### To maintain efficiency when working with large data, you will want to ensure you have a GPU connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809c5ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c206eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f1104f",
   "metadata": {},
   "source": [
    "## Set Datapath and Load in Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd43f571",
   "metadata": {},
   "source": [
    "#### Set datapath and file pattern for unprocessed data that you want to run predictions on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f10afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = '/scratch/users/prgiven/continuous_data/continuous_processed/'# replace me with datapath \n",
    "#input_file_pattern = os.path.join(datapath, 'unprocessed_data/2hr/', '*.npy') # replace me with directory and file pattern       \n",
    "input_file_pattern = os.path.join(datapath, 'unprocessed_data/day7/','*a*.npy') # replace me with directory and file pattern           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec3a268",
   "metadata": {},
   "source": [
    "#### Find filename and load data from numpy file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65511e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = sorted(tf.io.gfile.glob(input_file_pattern))\n",
    "print('Found {} files'.format(len(filenames)))\n",
    "print(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086d2da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(filenames[0])\n",
    "data=np.load(filenames[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29f409b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use this if data in segy format\n",
    "#import segyio\n",
    "#with segyio.open('/scratch/users/prgiven/FORGE/FORGE_78-32_iDASv3-P11_UTC190427171923.sgy', ignore_geometry=True) as f:\n",
    "#    FORGE = segyio.tools.collect(f.trace[:])\n",
    "#print(FORGE.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f68063",
   "metadata": {},
   "source": [
    "#### Quality check by printing data and checking data shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58e8dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46309e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcf3caa",
   "metadata": {},
   "source": [
    "## Data pre-processing functions\n",
    "\n",
    "**bp filter**: band-pass filters the data.\\\n",
    "**run prediction**: runs the model prediction on the data\\\n",
    "**preprocess**: runs bandpass on data, reshapes to model input size, clips amplitude values, and converts to float 32 format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3570f7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bpfilter(data,dt,bp_low,bp_high):\n",
    "    sos = scipy.signal.iirfilter(N=15,Wn=[bp_low,bp_high],btype='bandpass',fs=1/dt,output='sos')\n",
    "    return np.float32(scipy.signal.sosfilt(sos,data,axis=-1))\n",
    "\n",
    "def normalize(data, axis=-1):\n",
    "    stddev = np.std(data, axis=axis, keepdims=True)\n",
    "    return np.divide(data, stddev, out=np.zeros_like(data), where=stddev != 0)\n",
    "\n",
    "def med(data,axis=0):\n",
    "    data = data - np.median(data, axis=axis)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98929f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_prediction(inputs, model):\n",
    "    return model.predict(inputs, use_multiprocessing=True)\n",
    "\n",
    "def preprocess(data):\n",
    "    # crop it to input_height and width (cropping at the center)\n",
    "    data=med(data,axis=0)\n",
    "    data = bpfilter(data,0.002,30,200) #can change \n",
    "    data=normalize(data,axis=-1)\n",
    "    data = data.reshape((1, 400, 250, 1)) # model input shape\n",
    "    data = np.clip(data, -10, 10) # stats\n",
    "    return np.float32(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe00483",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cut data noise if necessary \n",
    "data=data[100:3968,0:7260000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093be230",
   "metadata": {},
   "outputs": [],
   "source": [
    "#double check data shape \n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349595c7",
   "metadata": {},
   "source": [
    "## Load ML Model and Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab48177",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_id = 'train_20210525_142709_cnn2d_modular_dec_baseline_' # Replace me\n",
    "datapath2='/home/users/prgiven/DAS_ML/microseismic-detection-ml'\n",
    "ckpt = '{}/models/{}/ckpt'.format(datapath2, job_id)\n",
    "model = tf.keras.models.load_model(ckpt)\n",
    "model.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15f1dcf",
   "metadata": {},
   "source": [
    "## Implement Sliding Windows, Pre-Procesing, and Running Prediction on Data\n",
    "\n",
    "The cell below will create sliding windows from continuous data with window size (400,250). It the pre-processes the data, and runs the prediction on the processed windows. The final output is in the form [inputted,logits] where the inputted is the inputted window, and the logits is the result of the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9aebf1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#data=np.load(filenames[0])\n",
    "def sliding_window(data):\n",
    "    n1=data.shape[0]\n",
    "    w1=400\n",
    "    d1=395 #sliding window with overlap of 5 cells\n",
    "    n2=data.shape[1]\n",
    "    w2=250\n",
    "    d2=245 #sliding window with overlap of 5 cells\n",
    "    #data_new=[]\n",
    "    num_windows1=len(range(0,n1-w1+1,d1))\n",
    "    #print(num_windows1)\n",
    "    num_windows2=len(range(0,n2-w2+1,d2))\n",
    "    #print(num_windows2)\n",
    "    logits=np.zeros((len(range(0,n1-w1+1,d1)),len(range(0,n2-w2+1,d2))))\n",
    "    inputted=np.zeros((num_windows1,num_windows2,400,250))\n",
    "    count1=0\n",
    "    for i1 in range(0,n1-w1+1,d1):\n",
    "        count2=0\n",
    "        print(count2)\n",
    "        for i2 in range(0,n2-w2+1,d2):\n",
    "            #print(i2)\n",
    "            data_new=preprocess(data[i1:i1+w1,i2:i2+w2])\n",
    "            data_new.shape\n",
    "            output = run_prediction(data_new, model)\n",
    "            logits[count1,count2] = output \n",
    "            inputted[count1,count2]=np.squeeze(data_new)\n",
    "            count2+=1\n",
    "        count1+=1\n",
    "    return inputted, logits\n",
    "    #return logits\n",
    "\n",
    "\n",
    "[inputted,logits]=sliding_window(data)       \n",
    "  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450fdd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check output sizes\n",
    "#print(inputted.shape)\n",
    "print(logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea0f0d5-a584-4f1e-bed9-5b7eacee7272",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/scratch/users/prgiven/continuous_data/continuous_processed/processed_data/day7/1a_logits.npy',logits)\n",
    "np.save('/scratch/users/prgiven/continuous_data/continuous_processed/processed_data/day7/1a_windows.npy',inputted)\n",
    "#np.save('/scratch/users/prgiven/continuous_data/continuous_processed/processed_data/20151024_091444/logits_second_half_20151024_091444_to_20151024_111444_chans2310_to_3334.npy',logits)\n",
    "#np.save('/scratch/users/prgiven/continuous_data/continuous_processed/processed_data/20151024_091444/inputted_second_half_20151024_091444_to_20151024_111444_chans2310_to_3334.npy',inputted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced6b9af",
   "metadata": {},
   "source": [
    "### Convert logits to probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0540e5",
   "metadata": {},
   "outputs": [],
   "source": [
    " probability = tf.nn.sigmoid(logits).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0346c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "probability.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e48755",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(probability[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c060b0a",
   "metadata": {},
   "source": [
    "### List High Probability Predictions (greater than 90% probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c3556a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"High Probability Events\",probability[probability>0.9])\n",
    "print(\"High Probability Event Indices\",np.where(probability>0.9))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950f99f5",
   "metadata": {},
   "source": [
    "### Total number of windows vs number of windows with predicted microseismic event with probability > 90%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06598410",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total Windows\",len(probability[probability>=0]))\n",
    "print(\"Number of Positive Windows with <90% Probability\",len(probability[probability>0.9]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6782e0",
   "metadata": {},
   "source": [
    "### Inputted windows predicted to have microseismic events (probability 90% or higher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dea8533",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "positive_predictions=np.where(probability>0.9)\n",
    "print(positive_predictions)\n",
    "positive_windows=inputted[positive_predictions[0],positive_predictions[1],:,:]\n",
    "print(positive_windows.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa853792",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/scratch/users/prgiven/continuous_data/continuous_processed/processed_data/day8/1a_pos_winds.npy',positive_windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a2006d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.animation as animation\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [10, 10]\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "fig, ax = plt.subplots()\n",
    "plt.xlabel('Relative distance along array (m)')\n",
    "plt.ylabel('Relative time (ms)')\n",
    "plt.title('Envelope Movie')\n",
    "\n",
    "\n",
    "\n",
    "ims = []\n",
    "for i in range(len(probability[probability>0.9])):\n",
    "    im = ax.imshow(abs((scipy.signal.hilbert2(positive_windows[i,:,:]))).T,cmap='rainbow',vmin=0,vmax=10, animated=True)\n",
    "    ims.append([im])\n",
    "\n",
    "ani = animation.ArtistAnimation(fig,ims,blit=True,interval=10)\n",
    "#ani = FuncAnimation(fig,ims,frames=123,interval=10)\n",
    "from IPython.display import HTML\n",
    "plt.rcParams['animation.embed_limit'] = 2**128\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc73ffc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change directory and desired saved file name \n",
    "f = \"/scratch/users/prgiven/3a_last_day.gif\" \n",
    "#writervideo = animation.FFMpegWriter(fps=1) \n",
    "ani.save(f, fps=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
